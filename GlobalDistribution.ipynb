{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Global Distribution with Azure Cosmos DB\n",
        "\n",
        "In this notebook we will compare the read and write latency from this Notebook located in Central US between three different Cosmos accounts.\n",
        "\n",
        "First, you must create three Cosmos DB accounts with the following configurations.\n",
        "\n",
        "- accounts 0: Single-master, single region, East US 2. \n",
        "- accounts 1: Single-master, two regions, East US 2 (master replica) and Central US (read replica). \n",
        "- accounts 2: Multi-master, two regions, East US 2 (master replica) and Central US (master replica).\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Resources\n",
        "In this cell connect to the three accounts, put into an array, then iterate over the array creating a database and container for each account."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logger = logging.getLogger()\n",
        "#logger.setLevel(logging.CRITICAL)\n",
        "\n",
        "import azure.cosmos.documents as documents\n",
        "import azure.cosmos.cosmos_client as cosmos\n",
        "from azure.cosmos.partition_key import PartitionKey\n",
        "import time\n",
        "\n",
        "#\n",
        "acct0_uri = \"<fill-me>\"\n",
        "acct0_key = \"<fill-me>\"\n",
        "acct0_connection_policy = documents.ConnectionPolicy()\n",
        "acct0_connection_policy.PreferredLocations = [\"East US 2\"]\n",
        "\n",
        "acct1_uri = \"<fill-me>\"\n",
        "acct1_key = \"<fill-me>\"\n",
        "acct1_connection_policy = documents.ConnectionPolicy()\n",
        "acct1_connection_policy.PreferredLocations = [\"Central US\"]\n",
        "\n",
        "acct2_uri = \"<fill-me>\"\n",
        "acct2_key = \"<fill-me>\"\n",
        "acct2_connection_policy = documents.ConnectionPolicy()\n",
        "acct2_connection_policy.PreferredLocations = [\"Central US\"]\n",
        "acct2_connection_policy.UseMultipleWriteLocations = True\n",
        "\n",
        "accounts = []\n",
        "\n",
        "accounts.append(cosmos.CosmosClient(url=acct1_uri, auth={'masterKey':acct1_key}, consistency_level=documents.ConsistencyLevel.Eventual, connection_policy=acct1_connection_policy))\n",
        "accounts.append(cosmos.CosmosClient(url=acct2_uri, auth={'masterKey':acct2_key}, consistency_level=documents.ConsistencyLevel.Eventual, connection_policy=acct2_connection_policy))\n",
        "accounts.append(cosmos.CosmosClient(url=acct3_uri, auth={'masterKey':acct3_key}, consistency_level=documents.ConsistencyLevel.Eventual, connection_policy=acct3_connection_policy))\n",
        "\n",
        "db_name = \"db1\"\n",
        "container_name  = \"c1\"\n",
        "db_query = \"select * from r where r.id = '{0}'\".format(db_name)\n",
        "container_query = \"select * from r where r.id = '{0}'\".format(container_name)\n",
        "\n",
        "for account in accounts:\n",
        "    # Create the database if it doesn't exist\n",
        "    db = list(account.query_databases(db_query))\n",
        "    if db:\n",
        "        print('Database already exists')\n",
        "    else:\n",
        "        account.create_database(id=db_name)\n",
        "        print('Database created')\n",
        "        time.sleep(3)\n",
        "    # Create the container\n",
        "    db = account.get_database_client(db_name)\n",
        "    containers = db.read_all_containers()\n",
        "    if(any(container['id'] == container_name for container in containers)):\n",
        "        db.delete_container(container_name); #delete and recreate to clear out old data\n",
        "        print('delete container')\n",
        "    pk = PartitionKey(path='/id', kind='Hash')\n",
        "    db.create_container(container_name, pk)\n",
        "    print('Container created')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-load Data\n",
        "In this cell, pre-load Account 0 and Account 1 with 100 items to prepare them for a read-latency test."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import json\n",
        "import random\n",
        "import uuid\n",
        "\n",
        "!{sys.executable} -m pip install Faker --user\n",
        "from faker import Faker\n",
        "fake = Faker()\n",
        "\n",
        "c0 = accounts[0].get_database_client(db_name).get_container_client(container_name)\n",
        "c1 = accounts[1].get_database_client(db_name).get_container_client(container_name)\n",
        "\n",
        "for x in range(0, 100):\n",
        "    item1 = {\n",
        "      \"id\": str(uuid.uuid4()),\n",
        "      \"name\": fake.name(),\n",
        "      \"city\": fake.city(),\n",
        "      \"state\": fake.state(),\n",
        "      \"uid\": random.randint(0,100)\n",
        "    }\n",
        "    item2 = item1\n",
        "    c0.create_item(body=item1)\n",
        "    c1.create_item(body=item2)\n",
        "print(\"Data load complete\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Latency Benchmark Single-master, Single-region\n",
        "This cell will benchmark the read latency for a Notebook running in Central US against a database with only a single read/write region in East US 2.\n",
        "\n",
        "This test will first query the container to get the self id's for 100 items. Then iterate through them and execute 100 point reads, measuring latency and RU cost for each read. It will then print the average latency and RU/s at the end."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Load a list of id's to do point reads with\n",
        "c = accounts[0].get_database_client(db_name).get_container_client(container_name)\n",
        "#%%sql --database {db_name} --container {container_name} --output ids\n",
        "sql = \"SELECT value c.id FROM c\"\n",
        "ids = list(c.query_items(query=sql, enable_cross_partition_query=True))\n",
        "\n",
        "l = []\n",
        "r = []\n",
        "\n",
        "for id in ids:\n",
        "    start = time.time()\n",
        "    response = c.read_item(item=id, partition_key=id)\n",
        "    end = time.time()\n",
        "    latency = round((end-start)*1000)\n",
        "    ru = float(c.client_connection.last_response_headers['x-ms-request-charge'])\n",
        "    l.append(latency)\n",
        "    r.append(ru)\n",
        "    #print(\"Latency: \" + str(latency) + \"ms, RU: \" + str(ru))\n",
        "\n",
        "l.sort()\n",
        "l = l[:99]\n",
        "avgL = round(sum(l)/len(l))\n",
        "avgR = round(sum(r)/len(r))\n",
        "\n",
        "print(\"Read Latency for Single-Master, Single-Region: Reader in Central US, Read Replica in East US 2\")\n",
        "print(\"Average Read Latency (P99): \" + str(avgL) + \"ms, Average RU: \" + str(avgR))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Latency Benchmark Single-master, Multi-region\n",
        "This cell will benchmark the read latency for a Notebook running in Central US against a database with a master replica in East US 2 and a read replica in Central US.\n",
        "\n",
        "This test will first query the container to get the self id's for 100 items. Then iterate through them and doing 100 point reads, measuring latency and RU cost for each read. It will then print the average latency and RU/s at the end."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Load a list of id's to do point reads with\n",
        "c = accounts[1].get_database_client(db_name).get_container_client(container_name)\n",
        "#%%sql --database {db_name} --container {container_name} --output ids\n",
        "sql = \"SELECT value c.id FROM c\"\n",
        "ids = list(c.query_items(query=sql, enable_cross_partition_query=True))\n",
        "\n",
        "l = []\n",
        "r = []\n",
        "\n",
        "for id in ids:\n",
        "    start = time.time()\n",
        "    response = c.read_item(item=id, partition_key=id)\n",
        "    end = time.time()\n",
        "    latency = round((end-start)*1000)\n",
        "    ru = float(c.client_connection.last_response_headers['x-ms-request-charge'])\n",
        "    l.append(latency)\n",
        "    r.append(ru)\n",
        "    #print(\"Latency: \" + str(latency) + \"ms, RU: \" + str(ru))\n",
        "\n",
        "l.sort()\n",
        "l = l[:99]\n",
        "avgL = round(sum(l)/len(l))\n",
        "avgR = round(sum(r)/len(r))\n",
        "\n",
        "print(\"Read Latency for Single-Master, Multi-Region: Reader in Central US, Read Replica in Central US\")\n",
        "print(\"Average Read Latency (P99): \" + str(avgL) + \"ms, Average RU: \" + str(avgR))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write Latency Benchmark Single-master, Multi-region\n",
        "\n",
        "This cell will benchmark the write latency for a Notebook running in Central US against a database with it's write replica in East US 2.\n",
        "\n",
        "This test will first generate 100 items to insert. Then iterate through the list and do 100 inserts, measuring latency and RU cost for each write. It will then print the average write latency and RU/s at the end."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "c = accounts[1].get_database_client(db_name).get_container_client(container_name)\n",
        "\n",
        "l = []\n",
        "r = []\n",
        "items = []\n",
        "\n",
        "fake = Faker()\n",
        "print(\"create 100 items for test\")\n",
        "for x in range(0, 100):\n",
        "    item = {\n",
        "      \"id\": str(uuid.uuid4()),\n",
        "      \"name\": fake.name(),\n",
        "      \"city\": fake.city(),\n",
        "      \"state\": fake.state(),\n",
        "      \"uid\": random.randint(0,100)\n",
        "    }\n",
        "    items.append(item)\n",
        "    \n",
        "for item in items:\n",
        "    start = time.time()\n",
        "    c.create_item(body=item)\n",
        "    end = time.time()\n",
        "    latency = round((end-start)*1000)\n",
        "    ru = float(c.client_connection.last_response_headers['x-ms-request-charge'])\n",
        "    l.append(latency)\n",
        "    r.append(ru)\n",
        "    #print(\"Write Latency: \" + str(latency) + \"ms, RU: \" + str(ru))\n",
        "\n",
        "l.sort()\n",
        "l = l[:99]\n",
        "avgL = round(sum(l)/len(l))\n",
        "avgR = round(sum(r)/len(r))\n",
        "\n",
        "print(\"Write Latency for Single-Master, Multi-Region: Writer in Central US, Write Replica in East US 2\")\n",
        "print(\"Average Write Latency (P99): \" + str(avgL) + \"ms, Average RU: \" + str(avgR))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write Latency Benchmark Multi-master, Multi-region\n",
        "\n",
        "This cell will benchmark the write latency for a Notebook running in Central US against a multi-master database in East US 2 and Central US regions.\n",
        "\n",
        "This test will first generate 100 items to insert. Then iterate through the list and do 100 inserts, measuring latency and RU cost for each write. It will then print the average write latency and RU/s at the end."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "c = accounts[2].get_database_client(db_name).get_container_client(container_name)\n",
        "\n",
        "l = []\n",
        "r = []\n",
        "items = []\n",
        "\n",
        "fake = Faker()\n",
        "print(\"create 100 items for test\")\n",
        "for x in range(0, 100):\n",
        "    item = {\n",
        "      \"id\": str(uuid.uuid4()),\n",
        "      \"name\": fake.name(),\n",
        "      \"city\": fake.city(),\n",
        "      \"state\": fake.state(),\n",
        "      \"uid\": random.randint(0,100)\n",
        "    }\n",
        "    items.append(item)\n",
        "    \n",
        "for item in items:\n",
        "    start = time.time()\n",
        "    c.create_item(body=item)\n",
        "    end = time.time()\n",
        "    latency = round((end-start)*1000)\n",
        "    ru = float(c.client_connection.last_response_headers['x-ms-request-charge'])\n",
        "    l.append(latency)\n",
        "    r.append(ru)\n",
        "    print(\"Write Latency: \" + str(latency) + \"ms, RU: \" + str(ru))\n",
        "\n",
        "l.sort()\n",
        "l = l[:99]\n",
        "avgL = round(sum(l)/len(l))\n",
        "avgR = round(sum(r)/len(r))\n",
        "\n",
        "print(\"Write Latency for Multi-Master, Multi-Region: Writer in Central US, Write Replica in Central US\")\n",
        "print(\"Average Write Latency (P99): \" + str(avgL) + \"ms, Average RU: \" + str(avgR))\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "nteract": {
      "version": "dataExplorer 1.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}